{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409d0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d656f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.25, 0.25, 0.25])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd8eaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_built() and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbb968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "NUM_CLASSES = 38 # 37 + 1 blank\n",
    "CTC_LABELS = [\n",
    "    \"<BLANK>\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"-\", \n",
    "    \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \n",
    "    \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"\n",
    "]\n",
    "COCO_TO_CTC = {\n",
    "    1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10,\n",
    "    11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16,\n",
    "    18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24,\n",
    "    26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32,\n",
    "    34: 33, 35: 34, 36: 35, 37: 36, 38: 37\n",
    "}\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663584a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "class plate_OCR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.features = nn.Sequential( #bruh it was pooling too much\n",
    "            resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool,\n",
    "            resnet.layer1, resnet.layer2\n",
    "        ) \n",
    "        #self.dimension_reduction = nn.Linear(1024, 512)\n",
    "        self.rnn = nn.LSTM(input_size=512, hidden_size=128, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.classify = nn.Linear(128 * 2, NUM_CLASSES)\n",
    "        with torch.no_grad():\n",
    "            self.classify.bias.fill_(0.)\n",
    "            self.classify.bias[0] = -2.0 \n",
    "        self.height_conv = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(16, 1), stride=(1, 1), padding=0, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.features(x) \n",
    "        x = self.relu(self.height_conv(x)) \n",
    "        x = x.squeeze(2) \n",
    "        x = x.permute(0, 2, 1) \n",
    "        #print(x.shape)\n",
    "        #x = self.dimension_reduction(x)\n",
    "        #print(x.shape)\n",
    "        rnn, _ = self.rnn(x)\n",
    "        result = self.classify(rnn)\n",
    "        return F.log_softmax(result, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3ad363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(result):\n",
    "    pred = result.argmax(-1).squeeze(0).tolist()\n",
    "    prev = -1\n",
    "    output = []\n",
    "    for p in pred:\n",
    "        if p != prev and p != len(CHARS):\n",
    "            output.append(CHARS[p])\n",
    "        prev = p\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c2ceb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from number_coco import license_coco\n",
    "from number_coco import license_collate\n",
    "from torch.utils.data import DataLoader\n",
    "''' for some reason this line wouldn't work here so reput at the top\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "'''\n",
    "X_train = \"../data/license_numbers/train/images\"\n",
    "y_train = \"../data/license_numbers/train/annotations.json\"\n",
    "\n",
    "train_dataset = license_coco(root=X_train, ann_file=y_train, transforms=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, prefetch_factor=2, persistent_workers=True, collate_fn=license_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6993cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plate_OCR().to(device)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde43b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_train_loader = iter(train_loader)\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea14dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  2,  2,  2,  3,  2,  9, 14,  2, 24, 10,  3,  8, 34, 34, 23,  5,  5,\n",
      "        10, 19, 28, 35, 32, 31, 10, 25,  4])\n"
     ]
    }
   ],
   "source": [
    "images, targets, target_lengths = next(testing_train_loader)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c83683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.3916\n",
      "tensor([27,  5, 19], device='cuda:0')\n",
      "tensor([12, 13, 22, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "images, targets, target_lengths = next(testing_train_loader)  # adjust to your loader\n",
    "images = images.to(device)\n",
    "targets = targets.to(device)\n",
    "target_lengths = target_lengths.to(device)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "log_output = model(images) # [B, T, C]\n",
    "log_output = log_output.permute(1, 0, 2) #[T, B, C]\n",
    "# Input lengths: full length for each sequence\n",
    "input_lengths = torch.full(size=(BATCH_SIZE,), fill_value=log_output.size(0), dtype=torch.long).to(device)\n",
    "\n",
    "assert all(input_lengths >= target_lengths), \"Target sequence too long for CTC\"\n",
    "# Loss computation\n",
    "\n",
    "loss = ctc_loss(log_output, targets, input_lengths, target_lengths)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Backward and optimize\n",
    "loss.backward()\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "optimizer.step()\n",
    "\n",
    "print(targets[:target_lengths[0]])\n",
    "predicted = log_output.argmax(dim=2)\n",
    "sample_pred = predicted[:, 0] \n",
    "print(sample_pred)\n",
    "predictions.append(sample_pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a565956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 13, 22, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e17ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5,     0] loss/50 = 0.1448 | LR = 1.00e-04\n",
      "[1/5,    50] loss/50 = 9.6155 | LR = 1.00e-04\n",
      "[1/5,   100] loss/50 = 4.6613 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[1/5,   150] loss/50 = 3.9393 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[1/5,   200] loss/50 = 3.8894 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[1/5,   250] loss/50 = -119063179.5394 | LR = 1.00e-04\n",
      "[1/5,   300] loss/50 = -309300035.8990 | LR = 1.00e-04\n",
      "[1/5,   350] loss/50 = 3.9312 | LR = 1.00e-04\n",
      "[1/5,   400] loss/50 = 3.8367 | LR = 1.00e-04\n",
      "[1/5,   450] loss/50 = 3.9021 | LR = 1.00e-04\n",
      "[1/5,   500] loss/50 = 3.9164 | LR = 1.00e-04\n",
      "[1/5,   550] loss/50 = 3.8232 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[1/5,   600] loss/50 = 3.8685 | LR = 1.00e-04\n",
      "[1/5,   650] loss/50 = 3.8925 | LR = 1.00e-04\n",
      "[1/5,   700] loss/50 = 3.8971 | LR = 1.00e-04\n",
      "[1/5,   750] loss/50 = 3.8529 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "[1/5,   800] loss/50 = 3.8798 | LR = 1.00e-04\n",
      "[1/5,   850] loss/50 = 3.8716 | LR = 1.00e-04\n",
      "[1/5,   900] loss/50 = 3.8520 | LR = 1.00e-04\n",
      "[1/5,   950] loss/50 = 3.8821 | LR = 1.00e-04\n",
      "[1/5,  1000] loss/50 = 3.8699 | LR = 1.00e-04\n",
      "[1/5,  1050] loss/50 = -238272.3639 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[1/5,  1100] loss/50 = 3.9209 | LR = 1.00e-04\n",
      "[1/5,  1150] loss/50 = 3.8636 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "Epoch 1 finished - avg loss: -18191910.1070\n",
      "\n",
      "[2/5,     0] loss/50 = 0.0782 | LR = 1.00e-04\n",
      "[2/5,    50] loss/50 = 3.9026 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[2/5,   100] loss/50 = 3.8608 | LR = 1.00e-04\n",
      "[2/5,   150] loss/50 = 3.9008 | LR = 1.00e-04\n",
      "[2/5,   200] loss/50 = 3.9349 | LR = 1.00e-04\n",
      "[2/5,   250] loss/50 = 3.8297 | LR = 1.00e-04\n",
      "[2/5,   300] loss/50 = 3.8741 | LR = 1.00e-04\n",
      "[2/5,   350] loss/50 = 3.8719 | LR = 1.00e-04\n",
      "[2/5,   400] loss/50 = 3.9036 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "[2/5,   450] loss/50 = 3.9331 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[2/5,   500] loss/50 = 3.9389 | LR = 1.00e-04\n",
      "[2/5,   550] loss/50 = 3.8636 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[2/5,   600] loss/50 = 3.8476 | LR = 1.00e-04\n",
      "[2/5,   650] loss/50 = 3.8658 | LR = 1.00e-04\n",
      "[2/5,   700] loss/50 = 3.8248 | LR = 1.00e-04\n",
      "[2/5,   750] loss/50 = 3.9488 | LR = 1.00e-04\n",
      "[2/5,   800] loss/50 = 3.9034 | LR = 1.00e-04\n",
      "[2/5,   850] loss/50 = -19479234.6127 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[2/5,   900] loss/50 = 3.8466 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[2/5,   950] loss/50 = 3.9266 | LR = 1.00e-04\n",
      "[2/5,  1000] loss/50 = 3.8498 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[2/5,  1050] loss/50 = 3.8641 | LR = 1.00e-04\n",
      "[2/5,  1100] loss/50 = 3.9045 | LR = 1.00e-04\n",
      "[2/5,  1150] loss/50 = 3.8853 | LR = 1.00e-04\n",
      "Epoch 2 finished - avg loss: -826788.9485\n",
      "\n",
      "[3/5,     0] loss/50 = 0.0796 | LR = 1.00e-04\n",
      "[3/5,    50] loss/50 = -22008682124406.2891 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   100] loss/50 = -265299521695.0753 | LR = 1.00e-04\n",
      "[3/5,   150] loss/50 = 4.8082 | LR = 1.00e-04\n",
      "[3/5,   200] loss/50 = 4.9851 | LR = 1.00e-04\n",
      "[3/5,   250] loss/50 = 4.9056 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   300] loss/50 = 4.9300 | LR = 1.00e-04\n",
      "[3/5,   350] loss/50 = 4.9455 | LR = 1.00e-04\n",
      "[3/5,   400] loss/50 = 5.0193 | LR = 1.00e-04\n",
      "[3/5,   450] loss/50 = -5075002814623.0557 | LR = 1.00e-04\n",
      "[3/5,   500] loss/50 = 4.9453 | LR = 1.00e-04\n",
      "[3/5,   550] loss/50 = 4.9569 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   600] loss/50 = 4.9503 | LR = 1.00e-04\n",
      "[3/5,   650] loss/50 = 5.0486 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   700] loss/50 = 4.9582 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   750] loss/50 = 4.9788 | LR = 1.00e-04\n",
      "[3/5,   800] loss/50 = 4.9554 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   850] loss/50 = 4.8772 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   900] loss/50 = 4.9850 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,   950] loss/50 = 5.0089 | LR = 1.00e-04\n",
      "[3/5,  1000] loss/50 = 5.0601 | LR = 1.00e-04\n",
      "[3/5,  1050] loss/50 = 4.9695 | LR = 1.00e-04\n",
      "[3/5,  1100] loss/50 = 4.9452 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[3/5,  1150] loss/50 = 4.8904 | LR = 1.00e-04\n",
      "Epoch 3 finished - avg loss: -1160822769975.5220\n",
      "\n",
      "[4/5,     0] loss/50 = 0.1023 | LR = 1.00e-04\n",
      "[4/5,    50] loss/50 = 4.8914 | LR = 1.00e-04\n",
      "[4/5,   100] loss/50 = 4.9536 | LR = 1.00e-04\n",
      "[4/5,   150] loss/50 = 4.9450 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,   200] loss/50 = 4.9186 | LR = 1.00e-04\n",
      "[4/5,   250] loss/50 = 4.9896 | LR = 1.00e-04\n",
      "[4/5,   300] loss/50 = 5.0191 | LR = 1.00e-04\n",
      "[4/5,   350] loss/50 = 4.9385 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,   400] loss/50 = 5.0198 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,   450] loss/50 = 5.0239 | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,   500] loss/50 = 4.9409 | LR = 1.00e-04\n",
      "[4/5,   550] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,   600] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,   650] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,   700] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,   750] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,   800] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,   850] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,   900] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,   950] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,  1000] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,  1050] loss/50 = nan | LR = 1.00e-04\n",
      "[4/5,  1100] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[4/5,  1150] loss/50 = nan | LR = 1.00e-04\n",
      "Epoch 4 finished - avg loss: nan\n",
      "\n",
      "[5/5,     0] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,    50] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "[5/5,   100] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "[5/5,   150] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   200] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "Skipping batch: target length exceeds input length.\n",
      "[5/5,   250] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   300] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   350] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   400] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   450] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   500] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   550] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   600] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   650] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[5/5,   700] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   750] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   800] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   850] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[5/5,   900] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,   950] loss/50 = nan | LR = 1.00e-04\n",
      "Skipping batch: target length exceeds input length.\n",
      "[5/5,  1000] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,  1050] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,  1100] loss/50 = nan | LR = 1.00e-04\n",
      "[5/5,  1150] loss/50 = nan | LR = 1.00e-04\n",
      "Epoch 5 finished - avg loss: nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = plate_OCR().to(device)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_loss   = 0.0\n",
    "    i = 0\n",
    "\n",
    "    for images, targets, target_lengths in train_loader:  # adjust to your loader\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        target_lengths = target_lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        log_output = model(images) # [B, T, C]\n",
    "        log_output = log_output.permute(1, 0, 2) #[T, B, C]\n",
    "\n",
    "\n",
    "        input_lengths = torch.full(size=(log_output.size(1),), fill_value=log_output.size(0), dtype=torch.long).to(device)\n",
    "        if (target_lengths > input_lengths).any():\n",
    "            # batch is impossible for CTC → skip\n",
    "            print(\"Skipping batch: target length exceeds input length.\")\n",
    "            optimizer.zero_grad(set_to_none=True)  # cheap no-op\n",
    "            continue    \n",
    "\n",
    "\n",
    "        loss = ctc_loss(log_output, targets, input_lengths, target_lengths)\n",
    "        #print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_val = loss.item()\n",
    "        running_loss += loss_val\n",
    "        epoch_loss   += loss_val\n",
    "        \n",
    "        if i % 50 == 0 or i == len(train_loader):\n",
    "            print(f\"[{epoch+1}/{epochs}, {i:5d}] \"\n",
    "                f\"loss/50 = {running_loss/50:.4f} | \"\n",
    "                f\"LR = {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "            running_loss = 0.0\n",
    "        i += 1\n",
    "        \n",
    "    print(f\"Epoch {epoch+1} finished - avg loss: {epoch_loss/len(train_loader):.4f}\\n\")\n",
    "\n",
    "torch.save(model.state_dict(), \"number_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = \"../data/license_numbers/test/images\"\n",
    "y_test = \"../data/license_numbers/test/annotations.json\"\n",
    "\n",
    "test_dataset = license_coco(root=X_test, ann_file=y_test, transforms=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4, prefetch_factor=2, persistent_workers=True, collate_fn=license_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b74fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, target_lengths = next(iter(train_loader))\n",
    "\n",
    "images = images.to(device)\n",
    "targets = targets.to(device)\n",
    "target_lengths = target_lengths.to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(images)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d7a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchCuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
