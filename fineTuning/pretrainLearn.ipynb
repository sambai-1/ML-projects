{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1151117a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/opt/anaconda3/envs/torch/lib/python3.11/site-packages/pyarrow/lib.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN4absl12lts_2025012712log_internal10LogMessagelsIhTnNSt3__19enable_ifIXntsr4absl16HasAbslStringifyIT_EE5valueEiE4typeELi0EEERS2_RKS6_\n  Referenced from: <B540F52C-E20A-301B-B105-287BA4CB5B4A> /opt/anaconda3/envs/torch/lib/libre2.11.dylib\n  Expected in:     <621B4947-F73F-3962-8DDB-2484D6B77411> /opt/anaconda3/envs/torch/lib/libabsl_log_internal_message.2501.0.0.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/torch/lib/python3.11/site-packages/datasets/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m3.6.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/torch/lib/python3.11/site-packages/datasets/arrow_dataset.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpa\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpc\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m url_to_fs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/torch/lib/python3.11/site-packages/pyarrow/__init__.py:65\u001b[39m\n\u001b[32m     63\u001b[39m _gc_enabled = _gc.isenabled()\n\u001b[32m     64\u001b[39m _gc.disable()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_lib\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[32m     67\u001b[39m     _gc.enable()\n",
      "\u001b[31mImportError\u001b[39m: dlopen(/opt/anaconda3/envs/torch/lib/python3.11/site-packages/pyarrow/lib.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN4absl12lts_2025012712log_internal10LogMessagelsIhTnNSt3__19enable_ifIXntsr4absl16HasAbslStringifyIT_EE5valueEiE4typeELi0EEERS2_RKS6_\n  Referenced from: <B540F52C-E20A-301B-B105-287BA4CB5B4A> /opt/anaconda3/envs/torch/lib/libre2.11.dylib\n  Expected in:     <621B4947-F73F-3962-8DDB-2484D6B77411> /opt/anaconda3/envs/torch/lib/libabsl_log_internal_message.2501.0.0.dylib"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import TFAutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921f20b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")\n",
    "# auto classifyier provided by hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b72d6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9993934631347656}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Alice was excited to go the island but it didn't live up to the hype.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b72993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9946909546852112}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Bob doesn't do well in group situations but he said it wasn't bad.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a538297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 4921, in from_pretrained\n    config, torch_dtype, dtype_orig = _get_torch_dtype(\n                                      ^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 1349, in _get_torch_dtype\n    state_dict = load_state_dict(\n                 ^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5001, in from_pretrained\n    ) = cls._load_pretrained_model(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5262, in _load_pretrained_model\n    load_state_dict(checkpoint_files[0], map_location=\"meta\", weights_only=weights_only).keys()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nwhile loading with BartForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 4921, in from_pretrained\n    config, torch_dtype, dtype_orig = _get_torch_dtype(\n                                      ^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 1349, in _get_torch_dtype\n    state_dict = load_state_dict(\n                 ^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5001, in from_pretrained\n    ) = cls._load_pretrained_model(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5262, in _load_pretrained_model\n    load_state_dict(checkpoint_files[0], map_location=\"meta\", weights_only=weights_only).keys()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m summarizer = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msummarization\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/__init__.py:1008\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1007\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n\u001b[32m   1020\u001b[39m \u001b[38;5;66;03m# Check which preprocessing classes the pipeline uses\u001b[39;00m\n\u001b[32m   1021\u001b[39m \u001b[38;5;66;03m# None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py:332\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback.items():\n\u001b[32m    331\u001b[39m             error += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    333\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    334\u001b[39m         )\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    337\u001b[39m     framework = infer_framework(model.\u001b[34m__class__\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 4921, in from_pretrained\n    config, torch_dtype, dtype_orig = _get_torch_dtype(\n                                      ^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 1349, in _get_torch_dtype\n    state_dict = load_state_dict(\n                 ^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5001, in from_pretrained\n    ) = cls._load_pretrained_model(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5262, in _load_pretrained_model\n    load_state_dict(checkpoint_files[0], map_location=\"meta\", weights_only=weights_only).keys()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nwhile loading with BartForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 4921, in from_pretrained\n    config, torch_dtype, dtype_orig = _get_torch_dtype(\n                                      ^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 1349, in _get_torch_dtype\n    state_dict = load_state_dict(\n                 ^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 315, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5001, in from_pretrained\n    ) = cls._load_pretrained_model(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 5262, in _load_pretrained_model\n    load_state_dict(checkpoint_files[0], map_location=\"meta\", weights_only=weights_only).keys()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 560, in load_state_dict\n    check_torch_load_is_safe()\n  File \"/opt/anaconda3/envs/torch/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 1606, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\n\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Hans Niemann is launching a counterattack in his dispute with chess world \n",
    "champion Magnus Carlsen, filing a federal lawsuit that accuses Carlsen of \n",
    "maliciously colluding with others to defame the 19-year-old grandmaster and \n",
    "ruin his career.\n",
    "\n",
    "It's the latest move in a scandal that has injected unprecedented levels of \n",
    "drama into the world of elite chess since early September, when Carlsen \n",
    "suggested Niemann's upset victory over him at the Sinquefield Cup tournament \n",
    "in St. Louis was the result of cheating.\n",
    "\n",
    "Niemann wants a federal court in Missouri's eastern district to award him at \n",
    "least $100 million in damages. Defendants in the lawsuit include Carlsen, his \n",
    "company Play Magnus Group, the online platform Chess.com and its leader, Danny \n",
    "Rensch, along with grandmaster Hikaru Nakamura.\n",
    "\"\"\"\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bruh very useful no halucination?\n",
    "context=\"\"\"\n",
    "Hugging Face was founded in 2016 by Clément Delangue, Julien Chaumond, and \n",
    "Thomas Wolf originally as a company that developed a chatbot app targeted at \n",
    "teenagers.[2] After open-sourcing the model behind the chatbot, the company \n",
    "pivoted to focus on being a platform for democratizing machine learning. In March \n",
    "2021, Hugging Face raised $40 million in a Series B funding round.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Who are the Hugging Face founders?\"\n",
    "\n",
    "qa(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a548c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# however, although an answer might be correct, it might not be the wanted one\n",
    "question = \"What does Hugging Face do?\"\n",
    "qa(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee54aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
