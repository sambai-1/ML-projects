{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc113ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install conda-forge::bpemb\n",
    "from bpemb import BPEmb\n",
    "bpemb_en = BPEmb(\n",
    "    lang=\"en\",\n",
    "    vs=10000,\n",
    "    dim=100,\n",
    "    cache_dir=\"data\",\n",
    "    model_file=\"../../data/bpemb/bpemb.model\",\n",
    "    emb_file=\"../../data/bpemb/bpemb_vectors.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480d24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.305548 -0.325598 -0.134716 -0.078735 -0.660545  0.076211 -0.735487\n",
      "  0.124533 -0.294402  0.459688  0.030137  0.174041 -0.224223  0.486189\n",
      " -0.504649 -0.459699  0.315747  0.477885  0.091398  0.427867  0.016524\n",
      " -0.076833 -0.899727  0.493158 -0.022309 -0.422785 -0.154148  0.204981\n",
      "  0.379834  0.070588  0.196073 -0.368222  0.473406  0.007409  0.004303\n",
      " -0.007823 -0.19103  -0.202509  0.109878 -0.224521 -0.35741  -0.611633\n",
      "  0.329958 -0.212956 -0.497499 -0.393839 -0.130101 -0.216903 -0.105595\n",
      " -0.076007 -0.483942 -0.139704 -0.161647  0.136985  0.415363 -0.360143\n",
      "  0.038601 -0.078804 -0.030421  0.324129  0.223378 -0.523636 -0.048317\n",
      " -0.032248 -0.117367  0.470519  0.225816 -0.222065 -0.225007 -0.165904\n",
      " -0.334389 -0.20157   0.572352 -0.268794  0.301929 -0.005563  0.387491\n",
      "  0.261031 -0.11613   0.074982 -0.008433  0.259987 -0.099893 -0.268875\n",
      " -0.054047 -0.534776 -0.111101 -0.051742  0.214114  0.04293   0.039873\n",
      " -0.453112  0.087382 -0.333201 -0.034079 -0.833045  0.155232 -1.132393\n",
      " -0.294766  0.327572]\n"
     ]
    }
   ],
   "source": [
    "print(bpemb_en.vectors[bpemb_en.words.index('car')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504288ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁where', '▁can', '▁i', '▁find', '▁a', '▁p', 'iz', 'zer', 'ia', '?']\n",
      "tensor([ 571,  280,  386, 1934,    4,   24,  248, 4339,  177, 9967])\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"Where can I find a pizzeria?\"\n",
    "tokens = bpemb_en.encode(sample_sentence)\n",
    "print(tokens)\n",
    "\n",
    "import torch\n",
    "device = 'cpu'\n",
    "token_seq = torch.tensor(bpemb_en.encode_ids(\"Where can I find a pizzeria?\")).to(device)\n",
    "print(token_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1869c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for:  Where can I find a pizzeria?\n",
      "tensor([[-8.7463e-01, -8.9760e-01, -1.3411e-01, -6.6376e-01,  9.1327e-01,\n",
      "         -1.3950e+00, -6.0384e-01,  1.8610e+00,  5.9130e-03,  9.7661e-01,\n",
      "          3.1923e-01,  1.2676e+00],\n",
      "        [ 1.1055e+00, -1.5845e+00, -4.0840e-01, -1.2682e+00, -1.0185e-01,\n",
      "         -4.7967e-01,  1.1287e+00, -6.0515e-01, -4.6186e-01,  8.9609e-01,\n",
      "         -5.7444e-01,  7.9070e-01],\n",
      "        [ 1.6365e+00, -2.1626e+00, -6.0403e-01, -6.5807e-01,  3.6614e-01,\n",
      "         -4.9695e-02,  6.8056e-03, -8.7919e-01, -7.7395e-02,  1.0444e-02,\n",
      "          6.8102e-02, -4.7479e-01],\n",
      "        [-2.1261e+00,  2.2726e+00, -5.7704e-01,  2.5164e-01, -5.3282e-02,\n",
      "         -1.2597e+00, -1.1039e+00, -3.8213e-01, -7.2975e-01, -1.3232e-01,\n",
      "         -1.0422e+00,  1.0553e+00],\n",
      "        [-1.3604e+00,  7.2590e-01, -1.0385e-01,  1.5275e+00,  3.9906e-02,\n",
      "          6.4281e-02, -6.3645e-01,  6.0490e-01, -7.3768e-01,  6.5772e-01,\n",
      "         -1.3318e+00,  1.7726e-01],\n",
      "        [ 2.0911e-01, -1.3869e+00,  8.5671e-01, -6.0944e-01,  1.1805e-01,\n",
      "         -1.4461e+00,  1.2566e+00, -3.5600e-01, -4.3304e-01, -1.0146e+00,\n",
      "         -8.2945e-01,  1.8698e+00],\n",
      "        [-7.1592e-01, -2.8177e-01,  5.1266e-01, -1.2722e+00, -3.0634e-01,\n",
      "          1.2179e+00,  6.0328e-01,  1.6150e+00, -1.2875e-01, -2.2649e-01,\n",
      "         -1.3340e+00, -8.2726e-04],\n",
      "        [ 8.8216e-01,  1.9980e-01,  1.6938e+00,  1.2712e+00, -1.4321e-01,\n",
      "          8.4403e-01, -4.5657e-02, -2.3836e-01, -7.7283e-01,  5.6128e-02,\n",
      "         -1.6298e-01, -1.0956e+00],\n",
      "        [ 2.1925e-01,  9.9818e-01, -1.0168e+00, -2.1107e-01, -6.8748e-01,\n",
      "         -9.3898e-01,  4.7931e-01, -2.4908e+00,  2.6980e-01,  4.3346e-02,\n",
      "          1.8578e+00, -2.9200e-01],\n",
      "        [-1.9539e-01, -1.9212e-01, -1.5458e+00, -6.0922e-01,  7.3035e-01,\n",
      "          8.8221e-01,  5.9068e-01,  8.8754e-01, -5.3724e-01, -8.1175e-01,\n",
      "         -1.2649e+00, -1.6741e-01]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bpemb_vocab_size, bpemb_embed_size = bpemb_en.vectors.shape\n",
    "embed_dim = 12\n",
    "token_embedding = torch.nn.Embedding(bpemb_vocab_size, embed_dim).to(device)\n",
    "token_embeddings = token_embedding(token_seq)\n",
    "\n",
    "# The untrained embeddings for our sample sentence.\n",
    "print(\"Embeddings for: \", sample_sentence)\n",
    "print(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676a5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Embeddings for:  Where can I find a pizzeria?\n",
      "tensor([[ 0.1246,  0.7973, -1.2678,  0.1535, -2.6879, -1.4674,  1.7158, -0.1523,\n",
      "         -0.0535, -2.2563,  0.0050,  0.6399],\n",
      "        [ 0.9518, -0.8789, -0.5462,  0.4181, -0.2060,  0.4292, -0.3480, -0.2873,\n",
      "         -0.0808, -1.0258, -0.4338,  0.0543],\n",
      "        [-1.0192,  0.1910,  0.1743, -0.3879,  0.6084, -0.1201, -1.3427,  0.5509,\n",
      "         -0.2582, -0.3114, -0.8161, -0.7931],\n",
      "        [-0.5894,  0.2700,  0.2608,  0.4741, -0.9167, -0.1942, -0.5391,  1.1258,\n",
      "          0.3955, -0.0808,  0.1725, -1.5417],\n",
      "        [-1.9315, -1.3421,  0.7003, -0.1287, -0.6843, -0.1778,  0.7739, -0.0385,\n",
      "         -0.1611, -2.2844, -0.7751,  2.8328],\n",
      "        [ 0.3312,  0.8206,  0.4232, -0.2132, -1.0924,  1.3171, -1.6360,  0.6603,\n",
      "         -1.3691,  1.5146,  0.8216, -0.3161],\n",
      "        [ 0.3677, -0.3788, -1.2730,  0.3806,  0.0057,  0.4642,  1.3096, -0.8553,\n",
      "          2.0010, -0.1971,  1.5171,  0.7705],\n",
      "        [-0.3760, -1.9196, -0.0919, -0.9719,  0.3195, -1.9421,  0.4546,  0.5703,\n",
      "         -0.3683, -1.1948,  1.3490,  0.4728],\n",
      "        [-0.7070,  3.1281, -0.1093, -1.4209,  0.3314, -0.0134, -1.0738, -0.6121,\n",
      "         -0.7860,  0.4110, -0.9571,  0.5035],\n",
      "        [-0.8070, -1.8476,  1.1498, -1.1528, -0.7490, -0.6620,  0.6420, -0.3959,\n",
      "          0.2236, -1.0462, -1.2475, -2.1672]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#positional information now\n",
    "max_seq_len = 256\n",
    "position_embedding = torch.nn.Embedding(max_seq_len, embed_dim).to(device)\n",
    "\n",
    "pos_idx = torch.tensor(list(range(len(token_seq)))).to(device)\n",
    "print(pos_idx)\n",
    "\n",
    "position_embeddings = position_embedding(pos_idx)\n",
    "print(\"Embeddings for: \", sample_sentence)\n",
    "print(position_embeddings)\n",
    "\n",
    "input = position_embeddings + token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ae5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
