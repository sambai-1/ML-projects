{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "# some powerful stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0728a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5633eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"This is a sentence.\")\n",
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9829eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest is from https://colab.research.google.com/github/futuremojo/nlp-demystified/blob/main/notebooks/nlpdemystified_preprocessing.ipynb#scrollTo=BIoEJZ-IkHQ4\n",
    "s = \"He didn't want to pay $20 for this book.\"\n",
    "doc = nlp(s)\n",
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943cd407",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"He told Dr. Cook that he was done with the tests and would cook the results shortly.\"\n",
    "doc = nlp(s)\n",
    "print([t.lower_ if not t.is_sent_start else t for t in doc]) # might mess up if Cook and cook are diff things, but would save vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3be9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'every', 'they', 'latterly', 'my', 'doing', 'seem', 'and', 'do', 'could', 'still', 'myself', 'very', 'that', 'empty', 'down', 'into', 'thence', 'amount', 'forty', 'each', 'seeming', 'ca', 'see', \"'s\", 'mine', \"'ll\", 'wherein', 'ours', 'throughout', 'toward', 'whole', 'fifteen', 'noone', 'anyhow', '‘ll', 'unless', 'anywhere', '‘s', '’s', 'anyone', 'least', 'though', 'on', 'us', 'we', 'over', 'beyond', 'therein', 'therefore', 'should', 'twenty', 'cannot', 'three', 'only', 'except', 'he', 'been', 'an', 'which', '‘ve', 'last', 'thereby', 'n‘t', 'before', 'go', 'did', 'almost', 'move', 'just', 'nobody', 'sometimes', 'any', 'further', 'really', 'eight', 'otherwise', 'namely', 'also', 'with', 'upon', 'up', 'indeed', 'same', 'due', 'most', 'was', 'neither', 'how', 'whose', 'put', 'whereas', 'others', '’m', 'nevertheless', 'somehow', 'take', 'make', '’ll', 'through', 'of', 'give', 'their', 'might', \"n't\", 'wherever', 'will', 'ever', \"'d\", 'until', 'them', 'back', 'hereby', 'hence', 'thereafter', 'out', 'whom', 'several', 'our', 'however', 'more', 'alone', 'twelve', 'seemed', 'yours', 'becomes', \"'ve\", 'call', 'although', 'per', 'whenever', 'becoming', 'for', 'here', 'may', 'why', 'who', 'either', 'anyway', 'behind', 'in', 'your', 'few', 'or', 'these', 'become', 'someone', 'whoever', 'within', 'get', 'whence', 'whereupon', 'whatever', 'part', 'if', 'five', 'some', 'is', \"'m\", 'everyone', 'often', 'one', 'much', 'always', 'a', 'both', 'are', 'everything', 'him', 'what', 'else', 'during', 'along', 'quite', 'then', 'regarding', 'to', '‘m', 'mostly', 'the', 'show', 'hers', 'have', 're', 'those', 'but', 'something', 'from', 'around', 'no', 'herself', 'none', 'has', 'keep', 'side', 'top', 'again', '‘re', 'under', '’re', 'say', 'latter', 'you', 'be', 'hereupon', 'this', 'fifty', 'various', 'yourselves', 'used', 'everywhere', 'front', 'moreover', 'six', 'nowhere', 'less', 'does', 'own', 'than', 'between', 'onto', 'meanwhile', \"'re\", 'many', 'yet', '’ve', 'too', 'below', 'next', '’d', 'done', 'ourselves', 'thus', 'ten', '‘d', 'first', 'already', 'being', 'formerly', 'nine', 'eleven', 'off', 'would', 'seems', 'towards', 'hereafter', 'besides', 'two', 'full', 'please', 'about', 'four', 'now', 'became', 'i', 'all', 'its', 'himself', 'itself', 'using', 'yourself', 'made', 'because', 'whither', 'well', 'had', 'there', 'enough', 'sometime', 'me', 'whereafter', 'another', 'his', 'as', 'it', 'rather', 'since', 'after', 'amongst', 'without', 'afterwards', 'whether', 'her', 'at', 'were', 'beforehand', 'where', 'beside', 'so', 'name', 'when', 'sixty', 'anything', 'among', 'hundred', 'whereby', 'such', 'once', 'across', 'perhaps', 'other', 'third', 'serious', 'thru', 'bottom', 'together', 'not', 'never', 'am', 'herein', 'somewhere', 'by', 'nor', 'elsewhere', 'former', 'nothing', 'thereupon', 'she', 'even', 'themselves', 'against', 'must', 'via', 'n’t', 'can', 'above', 'while'}\n",
      "326\n",
      "[told, Dr., Lovato, tests, post, results, shortly, .]\n"
     ]
    }
   ],
   "source": [
    "# spaCy's default stop word list.\n",
    "print(nlp.Defaults.stop_words)\n",
    "print(len(nlp.Defaults.stop_words))\n",
    "print([t for t in doc if not t.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a07aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[0])\n",
    "print(type(doc[0]))\n",
    "print(doc[0:3])\n",
    "print(type(doc[0:3]))\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ab332",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"Either the well was very deep, or she fell very slowly, for she \n",
    "had plenty of time as she went down to look about her and to wonder what \n",
    "was going to happen next. First, she tried to look down and make out what \n",
    "she was coming to, but it was too dark to see anything; then she looked at \n",
    "the sides of the well, and noticed that they were filled with cupboards and \n",
    "book-shelves; here and there she saw maps and pictures hung upon pegs.\"\"\"\n",
    "\n",
    "doc = nlp(s)\n",
    "\n",
    "# Look at individual sentences (there should be two 'Span' objects).\n",
    "print(list(doc.sents))\n",
    "print(list(doc.sents)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0958ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some excercizes\n",
    "\n",
    "# get all currencies\n",
    "# Expected output: \"$20\".\n",
    "s = \"He didn't want to pay $20 for this book.\"\n",
    "doc = nlp(s)\n",
    "ans = [doc[i].text + doc[i + 1].text for i in range(len(doc) - 1) if doc[i].is_currency and doc[i + 1].like_num]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom rules\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"gimme that\")  # phrase to tokenize\n",
    "print([w.text for w in doc])  # ['gimme', 'that']\n",
    "\n",
    "# Add special case rule\n",
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
    "\n",
    "# Check new tokenization\n",
    "print([w.text for w in nlp(\"gimme that\")])  # ['gim', 'me', 'that']\n",
    "\n",
    "nlp.tokenizer.add_special_case(\"...gimme...?\", [{\"ORTH\": \"...gimme...?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0085c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
